{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Analysis Using Kotlin\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.awt.Color\n",
    "import java.awt.Font\n",
    "import java.awt.Graphics2D\n",
    "import java.awt.Rectangle\n",
    "import java.awt.image.BufferedImage\n",
    "import java.io.File\n",
    "import javax.imageio.ImageIO\n",
    "import kotlin.random.Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load dates from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fun loadDatesFromCsv(filePath: String): List<String> {\n",
    "    val file = File(filePath)\n",
    "    val dates = mutableListOf<String>()\n",
    "\n",
    "    file.forEachLine { line ->\n",
    "        if (!line.startsWith(\"tweet_id,\")) {\n",
    "            val columns = line.split(\",(?=([^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\".toRegex())\n",
    "            if (columns.size > 2) {\n",
    "                dates.add(columns[2].trim()) // Extract date_created column\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return dates\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load text from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun loadTextFromCsv(filePath: String): List<String> {\n",
    "    val file = File(filePath)\n",
    "    val corpus = mutableListOf<String>()\n",
    "\n",
    "    file.forEachLine { line ->\n",
    "        if (!line.startsWith(\"tweet_id,\")) {\n",
    "            val columns = line.split(\",(?=([^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\".toRegex())\n",
    "            if (columns.size > 3) {\n",
    "                corpus.add(columns[3].trim().lowercase()) // Extract text column\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return corpus\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to count the total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun wordCount(corpus: List<String>): Int {\n",
    "    return corpus.sumOf { it.split(\"\\\\s+\".toRegex()).size }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to count the unique words (vocabulary size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun vocabularySize(corpus: List<String>): Int {\n",
    "    return corpus.flatMap { it.split(\"\\\\s+\".toRegex()) }\n",
    "        .filter { it.isNotBlank() }\n",
    "        .distinct()\n",
    "        .size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to count how many times a word appears in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun wordFrequency(corpus: List<String>): Map<String, Int> {\n",
    "    return corpus.flatMap { it.split(\"\\\\s+\".toRegex()) }\n",
    "        .filter { it.isNotBlank() } \n",
    "        .groupingBy { it }\n",
    "        .eachCount()\n",
    "        .toList()\n",
    "        .sortedByDescending { (_, count) -> count }\n",
    "        .toMap()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to count how many times a character was used in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun characterFrequency(corpus: List<String>): Map<Char, Int> {\n",
    "    return corpus.flatMap { it.toList() }\n",
    "        .groupingBy { it }\n",
    "        .eachCount()\n",
    "        .toList()\n",
    "        .sortedByDescending { (_, count) -> count }\n",
    "        .toMap()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the frequency of stop words in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun identifyStopWords(wordFrequencies: Map<String, Int>, stopWords: Set<String>): Map<String, Int> {\n",
    "    return wordFrequencies.filter { (word, _) -> stopWords.contains(word) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that displays the top 20 most used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun showTopFrequentWords(wordFrequencies: Map<String, Int>, topN: Int = 20) {\n",
    "    println(\"Top $topN Frequent Words:\")\n",
    "    wordFrequencies.entries.take(topN).forEach { (word, freq) ->\n",
    "        println(\"$word: $freq\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that displays the top 10 most used characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun showTopFrequentCharacters(charFrequencies: Map<Char, Int>, topN: Int = 10) {\n",
    "    println(\"Top $topN Frequent Characters:\")\n",
    "    charFrequencies.entries.take(topN).forEach { (char, freq) ->\n",
    "        println(\"$char: $freq\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that generates a word cloud using java.awts elements and outputs it as a png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun generateWordCloud(wordFrequencies: Map<String, Int>, outputFilePath: String) {\n",
    "    val width = 800\n",
    "    val height = 600\n",
    "\n",
    "    val image = BufferedImage(width, height, BufferedImage.TYPE_INT_RGB)\n",
    "    val graphics = image.createGraphics()\n",
    "\n",
    "    graphics.color = Color.WHITE\n",
    "    graphics.fillRect(0, 0, width, height)\n",
    "\n",
    "    val placedWords = mutableListOf<Rectangle>()\n",
    "\n",
    "    val sortedWords = wordFrequencies.entries.sortedByDescending { it.value }.take(20)\n",
    "    val centerX = width / 2\n",
    "    val centerY = height / 2\n",
    "\n",
    "    sortedWords.forEachIndexed { index, (word, frequency) ->\n",
    "        val fontSize = (10 + frequency * 5).coerceAtMost(60) // Clamp font size to a maximum\n",
    "        graphics.font = Font(\"Arial\", Font.BOLD, fontSize)\n",
    "\n",
    "        val wordWidth = graphics.fontMetrics.stringWidth(word)\n",
    "        val wordHeight = graphics.fontMetrics.height\n",
    "\n",
    "        var x: Int\n",
    "        var y: Int\n",
    "        var attempts = 0\n",
    "\n",
    "        while (true) {\n",
    "            if (index == 0 && attempts == 0) {\n",
    "                // Place the largest word at the center\n",
    "                x = centerX - wordWidth / 2\n",
    "                y = centerY + wordHeight / 2\n",
    "                val rect = Rectangle(x, y - wordHeight, wordWidth, wordHeight)\n",
    "                placedWords.add(rect)\n",
    "                break\n",
    "            } else {\n",
    "                // Random placement\n",
    "                x = (0 until (width - wordWidth)).random()\n",
    "                y = (wordHeight until (height - wordHeight)).random()\n",
    "\n",
    "                val newWordRect = Rectangle(x, y - wordHeight, wordWidth, wordHeight)\n",
    "                if (placedWords.none { it.intersects(newWordRect) }) {\n",
    "                    placedWords.add(newWordRect)\n",
    "                    break\n",
    "                }\n",
    "\n",
    "                attempts++\n",
    "                if (attempts > 100) {\n",
    "                    println(\"Failed to place word: $word after 100 attempts.\")\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Set random color\n",
    "        graphics.color = Color(\n",
    "            (50..255).random(),\n",
    "            (50..255).random(),\n",
    "            (50..255).random()\n",
    "        )\n",
    "\n",
    "        // Draw the word\n",
    "        graphics.drawString(word, x, y)\n",
    "    }\n",
    "\n",
    "    ImageIO.write(image, \"png\", File(outputFilePath))\n",
    "    graphics.dispose()\n",
    "\n",
    "    println(\"Word cloud saved to $outputFilePath\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val csvFilePath = \"fake_tweets.csv\"\n",
    "\n",
    "val corpus = loadTextFromCsv(csvFilePath)\n",
    "if (corpus.isEmpty()) {\n",
    "    println(\"No data loaded from CSV. Exiting program.\")\n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dates from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates and text data loaded successfully.\n",
      "Total dates: 100, Total text entries: 100\n"
     ]
    }
   ],
   "source": [
    "val dates = loadDatesFromCsv(csvFilePath)\n",
    "if (dates.isEmpty() || corpus.isEmpty()) {\n",
    "    println(\"No data loaded from CSV. Exiting program.\")\n",
    "}\n",
    "println(\"Dates and text data loaded successfully.\")\n",
    "println(\"Total dates: ${dates.size}, Total text entries: ${corpus.size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics:\n",
      "Total Word Count: 720\n",
      "Vocabulary Size: 530\n",
      "\n",
      "Word Frequency:\n",
      "#travel: 24\n",
      "#news: 20\n",
      "#food: 19\n",
      "#trending: 14\n",
      "#funny: 11\n",
      "😱: 7\n",
      "citizen: 3\n",
      "single: 3\n",
      "unit: 3\n",
      "itself: 3\n",
      "serve: 3\n",
      "of: 3\n",
      "forget: 3\n",
      "😭: 3\n",
      "soldier: 3\n",
      "throughout: 3\n",
      "bill: 3\n",
      "deep: 3\n",
      "measure.: 3\n",
      "instead: 3\n",
      "poor: 3\n",
      "🤯: 3\n",
      "church: 3\n",
      "deal: 3\n",
      "budget: 3\n",
      "through: 3\n",
      "political: 2\n",
      "show: 2\n",
      "pretty: 2\n",
      "race.: 2\n",
      "assume: 2\n",
      "book: 2\n",
      "but: 2\n",
      "minute: 2\n",
      "establish: 2\n",
      "ok: 2\n",
      "allow: 2\n",
      "👍: 2\n",
      "southern: 2\n",
      "one: 2\n",
      "or: 2\n",
      "people: 2\n",
      "ago: 2\n",
      "newspaper: 2\n",
      "them: 2\n",
      "front: 2\n",
      "yeah: 2\n",
      "power: 2\n",
      "agree: 2\n",
      "quickly: 2\n",
      "activity: 2\n",
      "purpose: 2\n",
      "my: 2\n",
      "heavy: 2\n",
      "news: 2\n",
      "side: 2\n",
      "well.: 2\n",
      "food: 2\n",
      "never: 2\n",
      "remain: 2\n",
      "media.: 2\n",
      "left: 2\n",
      "much: 2\n",
      "😍: 2\n",
      "view: 2\n",
      "teacher: 2\n",
      "south: 2\n",
      "continue: 2\n",
      "increase: 2\n",
      "happen: 2\n",
      "wall: 2\n",
      "education: 2\n",
      "several: 2\n",
      "future.: 2\n",
      "❤️: 2\n",
      "recent: 2\n",
      "to: 2\n",
      "what: 2\n",
      "reveal: 2\n",
      "center: 2\n",
      "🔥: 2\n",
      "other: 2\n",
      "production: 2\n",
      "half: 2\n",
      "us: 2\n",
      "themselves: 2\n",
      "cost: 2\n",
      "common: 1\n",
      "any.: 1\n",
      "camera: 1\n",
      "ready: 1\n",
      "@user2471465: 1\n",
      "😂: 1\n",
      "opportunity: 1\n",
      "family: 1\n",
      "style: 1\n",
      "manage: 1\n",
      "personal.: 1\n",
      "gun: 1\n",
      "throw: 1\n",
      "space.: 1\n",
      "international: 1\n",
      "onto.: 1\n",
      "carry.: 1\n",
      "@user1688028: 1\n",
      "@user9209275: 1\n",
      "@user3977988: 1\n",
      "author: 1\n",
      "try: 1\n",
      "born: 1\n",
      "close.: 1\n",
      "study: 1\n",
      "particular: 1\n",
      "around: 1\n",
      "early: 1\n",
      "official.: 1\n",
      "push: 1\n",
      "road: 1\n",
      "truth: 1\n",
      "foreign: 1\n",
      "impact.: 1\n",
      "near: 1\n",
      "note.: 1\n",
      "everything: 1\n",
      "body: 1\n",
      "watch: 1\n",
      "give: 1\n",
      "black: 1\n",
      "program.: 1\n",
      "investment: 1\n",
      "seat: 1\n",
      "image: 1\n",
      "country.: 1\n",
      "have: 1\n",
      "son.: 1\n",
      "value: 1\n",
      "live: 1\n",
      "against.: 1\n",
      "@user2429910: 1\n",
      "@user1377889: 1\n",
      "sell: 1\n",
      "defense.: 1\n",
      "@user4103324: 1\n",
      "let: 1\n",
      "training: 1\n",
      "player: 1\n",
      "money: 1\n",
      "last: 1\n",
      "outside.: 1\n",
      "nice: 1\n",
      "majority.: 1\n",
      "traditional: 1\n",
      "church.: 1\n",
      "@user8245551: 1\n",
      "@user2135995: 1\n",
      "@user6292973: 1\n",
      "down: 1\n",
      "look.: 1\n",
      "stop: 1\n",
      "soon: 1\n",
      "understand: 1\n",
      "offer: 1\n",
      "film: 1\n",
      "north.: 1\n",
      "stock: 1\n",
      "she: 1\n",
      "recently: 1\n",
      "sit.: 1\n",
      "@user4503087: 1\n",
      "way: 1\n",
      "strong: 1\n",
      "reality: 1\n",
      "@user7827230: 1\n",
      "@user8937370: 1\n",
      "@user3324810: 1\n",
      "red: 1\n",
      "bank: 1\n",
      "idea: 1\n",
      "for.: 1\n",
      "@user7381559: 1\n",
      "stuff: 1\n",
      "discussion: 1\n",
      "herself.: 1\n",
      "wish: 1\n",
      "recognize: 1\n",
      "card: 1\n",
      "reduce: 1\n",
      "like: 1\n",
      "what.: 1\n",
      "address: 1\n",
      "identify: 1\n",
      "our: 1\n",
      "democratic: 1\n",
      "wind: 1\n",
      "many.: 1\n",
      "alone: 1\n",
      "bed: 1\n",
      "where: 1\n",
      "standard: 1\n",
      "set: 1\n",
      "best: 1\n",
      "and.: 1\n",
      "@user6203857: 1\n",
      "@user3262293: 1\n",
      "place: 1\n",
      "present: 1\n",
      "idea.: 1\n",
      "@user6885835: 1\n",
      "@user1556628: 1\n",
      "@user9522192: 1\n",
      "carry: 1\n",
      "seven.: 1\n",
      "usually: 1\n",
      "first: 1\n",
      "create.: 1\n",
      "step: 1\n",
      "two: 1\n",
      "get: 1\n",
      "lay: 1\n",
      "research: 1\n",
      "experience.: 1\n",
      "behind: 1\n",
      "use.: 1\n",
      "@user3408932: 1\n",
      "@user7145885: 1\n",
      "billion: 1\n",
      "fear.: 1\n",
      "laugh: 1\n",
      "trial: 1\n",
      "out.: 1\n",
      "thousand: 1\n",
      "realize: 1\n",
      "account: 1\n",
      "western: 1\n",
      "student: 1\n",
      "decide: 1\n",
      "rich: 1\n",
      "huge.: 1\n",
      "@user4181955: 1\n",
      "available: 1\n",
      "who: 1\n",
      "article: 1\n",
      "risk: 1\n",
      "eight: 1\n",
      "republican: 1\n",
      "common.: 1\n",
      "@user7236593: 1\n",
      "@user1163717: 1\n",
      "seek: 1\n",
      "without: 1\n",
      "worry: 1\n",
      "kid.: 1\n",
      "read: 1\n",
      "store.: 1\n",
      "travel: 1\n",
      "talk: 1\n",
      "safe: 1\n",
      "executive.: 1\n",
      "point: 1\n",
      "green: 1\n",
      "pick: 1\n",
      "art.: 1\n",
      "everybody: 1\n",
      "cost.: 1\n",
      "year: 1\n",
      "arm: 1\n",
      "land.: 1\n",
      "@user7256536: 1\n",
      "@user1209600: 1\n",
      "@user7158333: 1\n",
      "responsibility: 1\n",
      "ground: 1\n",
      "determine.: 1\n",
      "their: 1\n",
      "brother: 1\n",
      "consider: 1\n",
      "growth.: 1\n",
      "@user2320316: 1\n",
      "police: 1\n",
      "arrive: 1\n",
      "trip: 1\n",
      "girl: 1\n",
      "together: 1\n",
      "mr.: 1\n",
      "strategy: 1\n",
      "apply: 1\n",
      "work: 1\n",
      "@user2990690: 1\n",
      "@user8757215: 1\n",
      "@user7932083: 1\n",
      "nothing: 1\n",
      "should: 1\n",
      "culture.: 1\n",
      "@user4634322: 1\n",
      "@user3857133: 1\n",
      "life: 1\n",
      "hear: 1\n",
      "fire: 1\n",
      "production.: 1\n",
      "@user7405522: 1\n",
      "@user4269179: 1\n",
      "@user8492077: 1\n",
      "hold: 1\n",
      "treat: 1\n",
      "ready.: 1\n",
      "@user5192434: 1\n",
      "@user8426351: 1\n",
      "@user3996017: 1\n",
      "start: 1\n",
      "cup: 1\n",
      "tax: 1\n",
      "threat: 1\n",
      "listen: 1\n",
      "significant.: 1\n",
      "@user6360836: 1\n",
      "@user7534925: 1\n",
      "quality: 1\n",
      "nature: 1\n",
      "in: 1\n",
      "finish: 1\n",
      "material.: 1\n",
      "glass: 1\n",
      "own: 1\n",
      "conference: 1\n",
      "describe: 1\n",
      "board.: 1\n",
      "important: 1\n",
      "attack: 1\n",
      "american: 1\n",
      "call.: 1\n",
      "remember.: 1\n",
      "@user1970001: 1\n",
      "program: 1\n",
      "car.: 1\n",
      "@user1807980: 1\n",
      "@user8797359: 1\n",
      "sound: 1\n",
      "full: 1\n",
      "later: 1\n",
      "collection: 1\n",
      "just: 1\n",
      "best.: 1\n",
      "capital: 1\n",
      "central: 1\n",
      "air: 1\n",
      "might: 1\n",
      "second: 1\n",
      "especially.: 1\n",
      "build: 1\n",
      "past: 1\n",
      "@user4413540: 1\n",
      "@user5799782: 1\n",
      "same: 1\n",
      "force: 1\n",
      "nation: 1\n",
      "health: 1\n",
      "which: 1\n",
      "age.: 1\n",
      "@user1369946: 1\n",
      "@user9694964: 1\n",
      "@user1955574: 1\n",
      "wide: 1\n",
      "cut: 1\n",
      "member: 1\n",
      "town: 1\n",
      "exactly.: 1\n",
      "@user6311962: 1\n",
      "relate: 1\n",
      "debate: 1\n",
      "region: 1\n",
      "bag: 1\n",
      "field.: 1\n",
      "@user2867954: 1\n",
      "@user5566781: 1\n",
      "such: 1\n",
      "contain: 1\n",
      "along: 1\n",
      "rather: 1\n",
      "letter: 1\n",
      "believe.: 1\n",
      "@user6075982: 1\n",
      "@user5938311: 1\n",
      "@user3462834: 1\n",
      "home: 1\n",
      "run: 1\n",
      "system: 1\n",
      "accept.: 1\n",
      "reason: 1\n",
      "loss: 1\n",
      "include: 1\n",
      "sense: 1\n",
      "popular: 1\n",
      "usually.: 1\n",
      "culture: 1\n",
      "new: 1\n",
      "happen.: 1\n",
      "size: 1\n",
      "fine: 1\n",
      "@user7556183: 1\n",
      "garden: 1\n",
      "affect.: 1\n",
      "more: 1\n",
      "position: 1\n",
      "he.: 1\n",
      "again: 1\n",
      "class: 1\n",
      "radio.: 1\n",
      "human: 1\n",
      "when.: 1\n",
      "meeting: 1\n",
      "exactly: 1\n",
      "resource: 1\n",
      "record.: 1\n",
      "myself: 1\n",
      "dream: 1\n",
      "these: 1\n",
      "including: 1\n",
      "guy.: 1\n",
      "@user3729306: 1\n",
      "@user2420357: 1\n",
      "@user2846281: 1\n",
      "coach: 1\n",
      "or.: 1\n",
      "law: 1\n",
      "interesting: 1\n",
      "fear: 1\n",
      "deep.: 1\n",
      "@user9153872: 1\n",
      "@user6577796: 1\n",
      "@user7569049: 1\n",
      "suggest: 1\n",
      "operation: 1\n",
      "each: 1\n",
      "picture: 1\n",
      "fill.: 1\n",
      "however: 1\n",
      "water: 1\n",
      "we: 1\n",
      "@user4640316: 1\n",
      "local: 1\n",
      "similar: 1\n",
      "ever: 1\n",
      "parent.: 1\n",
      "back: 1\n",
      "piece: 1\n",
      "oil: 1\n",
      "wonder: 1\n",
      "although: 1\n",
      "chair.: 1\n",
      "form: 1\n",
      "hope: 1\n",
      "child: 1\n",
      "site: 1\n",
      "begin.: 1\n",
      "large: 1\n",
      "change: 1\n",
      "serious.: 1\n",
      "especially: 1\n",
      "stand: 1\n",
      "care.: 1\n",
      "official: 1\n",
      "interview: 1\n",
      "evidence: 1\n",
      "third: 1\n",
      "answer: 1\n",
      "three: 1\n",
      "few.: 1\n",
      "fall: 1\n",
      "administration: 1\n",
      "city: 1\n",
      "indeed.: 1\n",
      "@user7273055: 1\n",
      "@user8439727: 1\n",
      "meet: 1\n",
      "beyond: 1\n",
      "grow: 1\n",
      "none: 1\n",
      "second.: 1\n",
      "accept: 1\n",
      "medical: 1\n",
      "public: 1\n",
      "necessary: 1\n",
      "way.: 1\n",
      "dinner: 1\n",
      "into: 1\n",
      "find: 1\n",
      "pass.: 1\n",
      "question: 1\n",
      "economy: 1\n",
      "entire: 1\n",
      "responsibility.: 1\n",
      "choice: 1\n",
      "so: 1\n",
      "between: 1\n",
      "long: 1\n",
      "huge: 1\n",
      "item.: 1\n",
      "during: 1\n",
      "learn: 1\n",
      "college: 1\n",
      "small: 1\n",
      "fight.: 1\n",
      "@user7553988: 1\n",
      "pattern: 1\n",
      "admit: 1\n",
      "modern: 1\n",
      "international.: 1\n",
      "@user1564069: 1\n",
      "anyone: 1\n",
      "require: 1\n",
      "happy.: 1\n",
      "@user7750878: 1\n",
      "@user7693675: 1\n",
      "@user1153580: 1\n",
      "note: 1\n",
      "executive: 1\n",
      "himself: 1\n",
      "look: 1\n",
      "expect: 1\n",
      "day.: 1\n",
      "yet: 1\n",
      "customer: 1\n",
      "window: 1\n",
      "something.: 1\n",
      "phone: 1\n",
      "report: 1\n",
      "all: 1\n",
      "suffer.: 1\n",
      "gas: 1\n",
      "where.: 1\n"
     ]
    }
   ],
   "source": [
    "val wordFrequencies = wordFrequency(corpus)\n",
    "\n",
    "val wordsSortedByFrequency = wordFrequencies.entries\n",
    "    .sortedByDescending { it.value } \n",
    "    .associate { it.toPair() } \n",
    "\n",
    "val charFrequencies = characterFrequency(corpus)\n",
    "\n",
    "val charsSortedByFrequency = charFrequencies.entries\n",
    ".sortedByDescending { it.value } \n",
    ".associate { it.toPair() }\n",
    "\n",
    "val totalWordCount = wordCount(corpus)\n",
    "val vocabSize = vocabularySize(corpus)\n",
    "\n",
    "println(\"\\nDescriptive Statistics:\")\n",
    "println(\"Total Word Count: $totalWordCount\")\n",
    "println(\"Vocabulary Size: $vocabSize\")\n",
    "println(\"\\nWord Frequency:\")\n",
    "wordsSortedByFrequency.forEach { (word, count) ->\n",
    "    println(\"$word: $count\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Frequency:\n",
      " : 620\n",
      "e: 534\n",
      "r: 340\n",
      "t: 276\n",
      "n: 257\n",
      "s: 251\n",
      "a: 247\n",
      "o: 241\n",
      "i: 220\n",
      "u: 197\n",
      "l: 184\n",
      "c: 135\n",
      "d: 133\n",
      "h: 112\n",
      ".: 100\n",
      "f: 89\n",
      "#: 88\n",
      "g: 83\n",
      "p: 82\n",
      "w: 73\n",
      "y: 73\n",
      "@: 71\n",
      "m: 68\n",
      "3: 60\n",
      "5: 59\n",
      "v: 59\n",
      "7: 58\n",
      "9: 56\n",
      "2: 53\n",
      "8: 48\n",
      "6: 45\n",
      "1: 44\n",
      "b: 40\n",
      "4: 37\n",
      "0: 37\n",
      "k: 20\n",
      "?: 17\n",
      "?: 7\n",
      "x: 7\n",
      "z: 6\n",
      "q: 5\n",
      "?: 3\n",
      "?: 3\n",
      "?: 3\n",
      "?: 2\n",
      "j: 2\n",
      "?: 2\n",
      "❤: 2\n",
      "️: 2\n",
      "?: 2\n",
      "?: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(\"\\nCharacter Frequency:\")\n",
    "charsSortedByFrequency.forEach { (character, count) ->\n",
    "    println(\"$character: $count\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency Analysis:\n",
      "Top 20 Frequent Words:\n",
      "#travel: 24\n",
      "#news: 20\n",
      "#food: 19\n",
      "#trending: 14\n",
      "#funny: 11\n",
      "😱: 7\n",
      "citizen: 3\n",
      "single: 3\n",
      "unit: 3\n",
      "itself: 3\n",
      "serve: 3\n",
      "of: 3\n",
      "forget: 3\n",
      "😭: 3\n",
      "soldier: 3\n",
      "throughout: 3\n",
      "bill: 3\n",
      "deep: 3\n",
      "measure.: 3\n",
      "instead: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(\"\\nFrequency Analysis:\")\n",
    "showTopFrequentWords(wordsSortedByFrequency, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop Word Identification:\n",
      "happen: 2\n",
      "try: 1\n",
      "where: 1\n",
      "new: 1\n",
      "although: 1\n",
      "form: 1\n",
      "none: 1\n",
      "medical: 1\n"
     ]
    }
   ],
   "source": [
    "val stopWords = setOf(\"although\", \"happen\", \"new\", \"none\", \"form\", \"something\", \"where\", \"try\", \"out\", \"medical\")\n",
    "\n",
    "val identifiedStopWords = identifyStopWords(wordFrequencies, stopWords)\n",
    "\n",
    "println(\"\\nStop Word Identification:\")\n",
    "identifiedStopWords.entries.take(10).forEach { (word, count) ->\n",
    "    println(\"$word: $count\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word cloud saved to wordcloud_custom.png\n"
     ]
    }
   ],
   "source": [
    "val outputFilePath = \"wordcloud_custom.png\"\n",
    "    generateWordCloud(wordFrequencies, outputFilePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
